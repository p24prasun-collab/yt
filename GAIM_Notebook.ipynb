{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GAIM Notebook - End-to-End Influencer Selection\n",
        "\n",
        "This notebook runs the complete pipeline without needing the web frontend or API server.\n",
        "\n",
        "What it does:\n",
        "- Expand campaign keywords\n",
        "- Search top X videos per keyword\n",
        "- Gather candidate channels and details\n",
        "- Sample comments and compute an \"organic\" score\n",
        "- Rank influencers using content match, keyword hits, comments, and optional network signal\n",
        "\n",
        "Prerequisites:\n",
        "- Python environment with project dependencies installed (`pip install -r requirements.txt`)\n",
        "- `.env` file at project root with `YOUTUBE_API_KEY`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: imports and environment\n",
        "import os\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Dict, Any\n",
        "import pandas as pd\n",
        "\n",
        "# Local project imports\n",
        "import sys\n",
        "sys.path.append('./backend')\n",
        "\n",
        "from youtube_api import YouTubeAPI\n",
        "from matcher import InfluencerMatcher\n",
        "from network_analyzer import NetworkAnalyzer\n",
        "from database import Database\n",
        "\n",
        "load_dotenv()\n",
        "YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
        "\n",
        "if not YOUTUBE_API_KEY:\n",
        "    raise RuntimeError(\"YOUTUBE_API_KEY not found. Create a .env at project root with YOUTUBE_API_KEY=your_key\")\n",
        "\n",
        "yt = YouTubeAPI(api_key=YOUTUBE_API_KEY)\n",
        "matcher = InfluencerMatcher()\n",
        "net = NetworkAnalyzer()\n",
        "db = Database()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helpers: keyword expansion, video search, comments score, selection\n",
        "\n",
        "async def expand_keywords(campaign_text: str, seed_keywords: List[str], max_related_per_keyword: int = 5) -> List[str]:\n",
        "    base_tokens = set()\n",
        "    for token in (campaign_text or '').lower().replace('\\n', ' ').split(' '):\n",
        "        token = token.strip('.,!?:;\"\\'()[]{}')\n",
        "        if len(token) >= 3:\n",
        "            base_tokens.add(token)\n",
        "    seeds = seed_keywords or list(base_tokens)\n",
        "\n",
        "    def variants(k: str) -> List[str]:\n",
        "        v = {k}\n",
        "        if k.endswith('ing'):\n",
        "            v.add(k[:-3])\n",
        "        if not k.endswith('s'):\n",
        "            v.add(k + 's')\n",
        "        if '-' in k:\n",
        "            v.add(k.replace('-', ' '))\n",
        "        if ' ' in k:\n",
        "            parts = k.split(' ')\n",
        "            if len(parts) == 2:\n",
        "                v.add(''.join(parts))\n",
        "        return list(v)\n",
        "\n",
        "    all_terms = set()\n",
        "    for s in seeds[:20]:\n",
        "        all_terms.update(variants(s.lower()))\n",
        "        try:\n",
        "            vids = await yt.search_videos(s, max_results=max_related_per_keyword, order='relevance')\n",
        "            freq: Dict[str, int] = {}\n",
        "            for v in vids:\n",
        "                text = (v.get('title', '') + ' ' + v.get('description', '')).lower()\n",
        "                for w in text.split():\n",
        "                    w = w.strip('.,!?:;\"\\'()[]{}')\n",
        "                    if len(w) >= 4 and w not in {'with','from','that','this','have','your','about','into','over','under','what','when','where','which','there'}:\n",
        "                        freq[w] = freq.get(w, 0) + 1\n",
        "            for w,_ in sorted(freq.items(), key=lambda x: x[1], reverse=True)[:max_related_per_keyword]:\n",
        "                all_terms.add(w)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return sorted(list(all_terms))\n",
        "\n",
        "async def search_top_videos(keywords: List[str], top_videos_per_keyword: int = 5, order: str = 'viewCount') -> Dict[str, List[Dict[str, Any]]]:\n",
        "    res: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for kw in keywords[:20]:\n",
        "        vids = await yt.search_videos(kw, max_results=top_videos_per_keyword, order=order)\n",
        "        res[kw] = vids\n",
        "        for v in vids:\n",
        "            if v.get('channel_id'):\n",
        "                db.save_videos(v.get('channel_id', ''), [v])\n",
        "    return res\n",
        "\n",
        "async def comment_organic_score(video_ids: List[str], max_comments_per_video: int = 50) -> float:\n",
        "    sample = video_ids[: min(3, len(video_ids))]\n",
        "    total = 0\n",
        "    unique_authors = set()\n",
        "    total_len = 0\n",
        "    repeated: Dict[str, int] = {}\n",
        "    for vid in sample:\n",
        "        try:\n",
        "            comments = await yt.get_video_comments(vid, max_results=max_comments_per_video)\n",
        "        except Exception:\n",
        "            comments = []\n",
        "        db.save_comments(vid, comments)\n",
        "        total += len(comments)\n",
        "        for c in comments:\n",
        "            author = c.get('author', '')\n",
        "            unique_authors.add(author)\n",
        "            text = (c.get('text', '') or '')[:200]\n",
        "            total_len += len(text)\n",
        "            key = text.lower().strip()\n",
        "            if len(key) >= 8:\n",
        "                repeated[key] = repeated.get(key, 0) + 1\n",
        "    if total == 0:\n",
        "        return 0.5\n",
        "    uniq_ratio = len(unique_authors) / total\n",
        "    avg_len = total_len / max(total, 1)\n",
        "    rep_penalty = min(max((max(repeated.values()) if repeated else 1) - 1, 0) / 10.0, 1.0)\n",
        "    len_score = max(min((avg_len - 10) / (120 - 10), 1.0), 0.0)\n",
        "    score = 0.6 * uniq_ratio + 0.4 * len_score\n",
        "    score *= (1.0 - 0.5 * rep_penalty)\n",
        "    return max(min(score, 1.0), 0.0)\n",
        "\n",
        "async def select_influencers(\n",
        "    campaign_text: str,\n",
        "    seed_keywords: List[str],\n",
        "    keywords: List[str] = None,\n",
        "    top_videos_per_keyword: int = 5,\n",
        "    past_videos_to_check: int = 5,\n",
        "    top_n: int = 20,\n",
        "    use_network: bool = False,\n",
        "    max_comments_per_video: int = 50,\n",
        "):\n",
        "    # 1) keywords\n",
        "    if not keywords:\n",
        "        keywords = await expand_keywords(campaign_text, seed_keywords)\n",
        "\n",
        "    # 2) search videos\n",
        "    kw_videos = await search_top_videos(keywords, top_videos_per_keyword, order='viewCount')\n",
        "\n",
        "    # 3) aggregate channels\n",
        "    channel_hits: Dict[str, int] = {}\n",
        "    channel_to_vids: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for vids in kw_videos.values():\n",
        "        for v in vids:\n",
        "            cid = v.get('channel_id', '')\n",
        "            if cid:\n",
        "                channel_hits[cid] = channel_hits.get(cid, 0) + 1\n",
        "                channel_to_vids.setdefault(cid, []).append(v)\n",
        "\n",
        "    # 4) channel details\n",
        "    channel_ids = list(channel_hits.keys())\n",
        "    channels_data = await yt.get_channels_details(channel_ids)\n",
        "\n",
        "    # 5) comments organic score per channel\n",
        "    channel_comment_score: Dict[str, float] = {}\n",
        "    for cid, vids in channel_to_vids.items():\n",
        "        sample_video_ids = [v.get('video_id') for v in vids if v.get('video_id')][:3]\n",
        "        channel_comment_score[cid] = await comment_organic_score(sample_video_ids, max_comments_per_video)\n",
        "\n",
        "    # 6) base match\n",
        "    matches = matcher.find_matches(\n",
        "        channels_data=channels_data,\n",
        "        brand_keywords=keywords or [],\n",
        "        target_audience=None,\n",
        "    )\n",
        "\n",
        "    # 7) optional network\n",
        "    pagerank_scores: Dict[str, float] = {}\n",
        "    if use_network and len(channels_data) > 1:\n",
        "        net_data = net.build_network(channels_data)\n",
        "        pr = net_data.get('metrics', {}).get('pagerank', {})\n",
        "        pagerank_scores = {cid: pr.get(cid, 0.0) for cid in [c['channel_id'] for c in channels_data]}\n",
        "\n",
        "    # 8) final score\n",
        "    enriched = []\n",
        "    for m in matches:\n",
        "        cid = m['channel_id']\n",
        "        hit_score = min(channel_hits.get(cid, 0) / max(len(keywords or []), 1), 1.0)\n",
        "        comment_score = channel_comment_score.get(cid, 0.5)\n",
        "        net_score = pagerank_scores.get(cid, 0.0)\n",
        "        final_score = 0.6 * m['match_score'] + 0.15 * hit_score + 0.2 * comment_score + 0.05 * net_score\n",
        "        enriched.append({\n",
        "            **m,\n",
        "            'hit_score': round(hit_score, 3),\n",
        "            'comment_score': round(comment_score, 3),\n",
        "            'network_score': round(net_score, 3),\n",
        "            'final_score': round(final_score, 4)\n",
        "        })\n",
        "\n",
        "    enriched.sort(key=lambda x: x['final_score'], reverse=True)\n",
        "    top = enriched[: top_n]\n",
        "    return top, keywords\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure your campaign here\n",
        "campaign_text = \"Launching an eco-friendly fitness water bottle for gym-goers\"\n",
        "seed_keywords = [\"eco fitness\", \"water bottle\", \"gym\"]\n",
        "\n",
        "# Controls\n",
        "TOP_VIDEOS_PER_KEYWORD = 5\n",
        "PAST_VIDEOS_TO_CHECK = 5\n",
        "TOP_N = 15\n",
        "USE_NETWORK = True\n",
        "MAX_COMMENTS_PER_VIDEO = 50\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ranked, used_keywords = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect_influencers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcampaign_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcampaign_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed_keywords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed_keywords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# set to a custom list to skip expansion\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_videos_per_keyword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP_VIDEOS_PER_KEYWORD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_videos_to_check\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPAST_VIDEOS_TO_CHECK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTOP_N\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_network\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_NETWORK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_comments_per_video\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_COMMENTS_PER_VIDEO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKeywords used (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(used_keywords)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(used_keywords[:\u001b[32m20\u001b[39m]), (\u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(used_keywords) > \u001b[32m20\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
            "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ],
      "source": [
        "# Run the pipeline\n",
        "\n",
        "ranked, used_keywords = asyncio.run(select_influencers(\n",
        "    campaign_text=campaign_text,\n",
        "    seed_keywords=seed_keywords,\n",
        "    keywords=None,  # set to a custom list to skip expansion\n",
        "    top_videos_per_keyword=TOP_VIDEOS_PER_KEYWORD,\n",
        "    past_videos_to_check=PAST_VIDEOS_TO_CHECK,\n",
        "    top_n=TOP_N,\n",
        "    use_network=USE_NETWORK,\n",
        "    max_comments_per_video=MAX_COMMENTS_PER_VIDEO,\n",
        "))\n",
        "\n",
        "print(f\"Keywords used ({len(used_keywords)}):\", ', '.join(used_keywords[:20]), ('...' if len(used_keywords) > 20 else ''))\n",
        "\n",
        "# Display results\n",
        "if ranked:\n",
        "    df = pd.DataFrame(ranked)\n",
        "    display(df[[\n",
        "        'channel_id', 'title', 'country', 'subscriber_count', 'video_count', 'view_count',\n",
        "        'match_score', 'hit_score', 'comment_score', 'network_score', 'final_score'\n",
        "    ]])\n",
        "else:\n",
        "    print(\"No results.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Save ranked results to CSV\n",
        "SAVE_CSV = True\n",
        "CSV_PATH = 'ranked_influencers.csv'\n",
        "\n",
        "if ranked and SAVE_CSV:\n",
        "    pd.DataFrame(ranked).to_csv(CSV_PATH, index=False)\n",
        "    print(f\"Saved to {CSV_PATH}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup aiohttp session\n",
        "asyncio.run(yt.close())\n",
        "print(\"Done.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
